{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img style=\"float: right;\" src=\"https://docs.expert.ai/logo.png\" width=\"150px\">\n",
    " \n",
    "# My first Notebook with expert.ai Detectors API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **expert.ai Natural Language API v2** (https://developer.expert.ai/) parses and \"understands\" large volumes of text.\n",
    "\n",
    "\n",
    "In this section we will explain how to install and use our Detectors API and then introduce some key concepts regarding Natural Language Processing.\n",
    "\n",
    "You can download this notebook and our Python SDK's source code from Github at https://github.com/therealexpertai/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Setup \n",
    "\n",
    "First of all, you have to install the __expert.ai-nlapi__ library using pip. \n",
    "\n",
    "* https://pypi.org/project/expertai-nlapi/\n",
    "\n",
    "Then, you will also need to install  __pandas__  library since it will be useful in order to create tables and show the results of the analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with NL API in Python\n",
    "Now you have to setup your account credentials; if you don't have them, you can get them at https://developer.expert.ai/ui/login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your environment variables with NL API credentials \n",
    "\n",
    "```bash\n",
    "SET EAI_USERNAME=YOUR_USER\n",
    "SET EAI_PASSWORD=YOUR_PASSWORD\n",
    "```\n",
    "or \n",
    "\n",
    "```bash\n",
    "export EAI_USERNAME=YOUR_USER\n",
    "export EAI_PASSWORD=YOUR_PASSWORD\n",
    "```\n",
    "\n",
    "as an alternative you can always add to your notebook the following statements\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ[\"EAI_USERNAME\"] = 'YOUR_USER'\n",
    "os.environ[\"EAI_PASSWORD\"] = 'YOUR_PASSWORD'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now let's play with Python and Natural Language Processing__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently our Detectors API support two languages (English and Italian).\n",
    "\n",
    "In order to run the Detector's analysis you have to define the text you want to analyze and the language model to be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expertai.nlapi.cloud.client import ExpertAiClient\n",
    "import json, os\n",
    "client = ExpertAiClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textsToAnalyze=[]\n",
    "for file in os.listdir(\"demo\"):\n",
    "    with open('demo/'+file) as f:\n",
    "        textsToAnalyze.append({'txt':f.read(),'fileName':file})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick run\n",
    "\n",
    "Now you can start using our Detectors API by just sending a text. \n",
    "\n",
    "This is how it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for textObj in textsToAnalyze:\n",
    "    documents.append({\n",
    "        'file': textObj['fileName'],\n",
    "        'res': client.detection(body={\"document\": {\"text\": textObj['txt']}}, params={'language': 'en','detector':'pii'})\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `detect` analysis for PII returns all the information in a document that could be considered sensitive since they could be used to identify a specific individual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataTable\n",
    "\n",
    "Generate dataTable extractions from demo texts in English:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "mapColoredCell = set()\n",
    "def coloredCell(s):\n",
    "    key = '-'.join(s.name[0:3])\n",
    "    if(key not in mapColoredCell):\n",
    "        mapColoredCell.add(key)\n",
    "        return ['border-top: 1px solid !important']\n",
    "    \n",
    "    return['']\n",
    "   \n",
    "\n",
    "dataToShow = []   \n",
    "for doc in documents:\n",
    "    mapInstances = {}\n",
    "    partianElements = []\n",
    "    fieldName=\"\"\n",
    "    for extraction in doc['res'].extractions:\n",
    "        \n",
    "        if extraction.template in mapInstances:\n",
    "            mapInstances[extraction.template] += 1\n",
    "        else:\n",
    "            mapInstances[extraction.template] = 1\n",
    "        dateCount=0;\n",
    "        for field in extraction.fields:\n",
    "            fieldName = field.name\n",
    "            if field.name == \"dateTime\":\n",
    "                dateCount+=1\n",
    "                fieldName+= \" #\"+str(dateCount)\n",
    "            row = {\n",
    "                \"file\" : doc['file'],\n",
    "                \"template\": extraction.template,\n",
    "                \"instance\" : '#' + str(mapInstances[extraction.template]),\n",
    "                'field':fieldName,\n",
    "                'value':field.value\n",
    "            }\n",
    "            partianElements.append(row)\n",
    "            dataToShow.append(row)\n",
    "    for e in partianElements:\n",
    "        inst = mapInstances[e['template']]\n",
    "        if inst == 1:\n",
    "            e['instance'] = ''\n",
    "            \n",
    "\n",
    "df = pd.DataFrame(dataToShow)\n",
    "df.set_index(['file','template', 'instance', 'field'], inplace=True)\n",
    "left_aligned_df = df.style.set_properties(**{'text-align': 'left', 'padding-left': '30px'})  \n",
    "left_aligned_df.apply(coloredCell,axis=1)\n",
    "display(left_aligned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON LD response\n",
    "Moreover, you can also retrive json-ld data by using the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    print(\"************************\")\n",
    "    print (doc['file']+\": \")\n",
    "    print(json.dumps(doc['res'].extra_data, indent=2, sort_keys=True))\n",
    "    print(\"************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job! Now you are an expert in the expert.ai community! \n",
    "\n",
    "Check out other language SDKs available on our [Github page](https://github.com/therealexpertai)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}